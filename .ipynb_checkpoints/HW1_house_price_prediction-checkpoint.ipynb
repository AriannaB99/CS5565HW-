{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uA3nmwPwyBMX"
   },
   "source": [
    "# Homework 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "stVyicl_yGIl"
   },
   "source": [
    "**Your name:** Arianna Bunnell\n",
    "\n",
    "**A-Number:** A02213719\n",
    "\n",
    "In this homework, we will build a model based on real house sale data from a [Kaggle competition](https://www.kaggle.com/c/house-prices-advanced-regression-techniques). This notebook contains codes to download the dataset, build and train a baseline model, and save the results in the submission format. Your jobs \n",
    "\n",
    "1.   Implement the preprocessing code\n",
    "\n",
    "2.   Developing a better model to reduce the prediction error. You can try any models you know.\n",
    "\n",
    "3.   Submitting your results into Kaggle and take a sceenshot of your score. Then replace the following image URL with your screenshot.\n",
    "\n",
    "![](score.png)\n",
    "\n",
    "4.   Submit the .IPYNB file to Canvas.\n",
    "    - Missing the output after execution may hurt your grade.\n",
    "\n",
    "## Accessing and Reading Data Sets\n",
    "\n",
    "The competition data is separated into training and test sets. Each record includes the property values of the house and attributes such as street type, year of construction, roof type, basement condition. The data includes multiple datatypes, including integers (year of construction), discrete labels (roof type), floating point numbers, etc.; Some data is missing and is thus labeled 'na'. The price of each house, namely the label, is only included in the training data set (it's a competition after all). The 'Data' tab on the competition tab has links to download the data.\n",
    "\n",
    "We will read and process the data using `pandas`, an [efficient data analysis toolkit](http://pandas.pydata.org/pandas-docs/stable/). Make sure you have `pandas` installed for the experiments in this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "Wx9ga3uzx9Mo",
    "outputId": "b112c1f6-93fe-43c5-85ff-a5d202ad91f8"
   },
   "outputs": [],
   "source": [
    "# If pandas is not installed, please uncomment and run the following line:\n",
    " #!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RFY8ZcFb_dBN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MYPxXoI20b98"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xgH-Yitf22sc"
   },
   "source": [
    "We downloaded the data into the current directory. To load the two CSV (Comma Separated Values) files containing training and test data respectively we use Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 399
    },
    "colab_type": "code",
    "id": "SnC1qnsy1TiZ",
    "outputId": "c10f9ba0-61cf-41d5-c8de-cd2145a408a6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2020-09-05 12:32:41--  https://raw.githubusercontent.com/d2l-ai/data/master/kaggle_house_pred_test.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.196.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.196.133|:443... connected.\n",
      "ERROR: cannot verify raw.githubusercontent.com's certificate, issued by 'CN=DigiCert SHA2 High Assurance Server CA,OU=www.digicert.com,O=DigiCert Inc,C=US':\n",
      "  Unable to locally verify the issuer's authority.\n",
      "To connect to raw.githubusercontent.com insecurely, use `--no-check-certificate'.\n",
      "--2020-09-05 12:32:41--  https://raw.githubusercontent.com/d2l-ai/data/master/kaggle_house_pred_train.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.196.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.196.133|:443... connected.\n",
      "ERROR: cannot verify raw.githubusercontent.com's certificate, issued by 'CN=DigiCert SHA2 High Assurance Server CA,OU=www.digicert.com,O=DigiCert Inc,C=US':\n",
      "  Unable to locally verify the issuer's authority.\n",
      "To connect to raw.githubusercontent.com insecurely, use `--no-check-certificate'.\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/d2l-ai/data/master/kaggle_house_pred_test.csv\n",
    "!wget https://raw.githubusercontent.com/d2l-ai/data/master/kaggle_house_pred_train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8F0Yfc2X2CPi"
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('kaggle_house_pred_train.csv')\n",
    "test_data = pd.read_csv('kaggle_house_pred_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nV7ywmUB25_h"
   },
   "source": [
    "The training data set includes 1,460 examples, 80 features, and 1 label., the test data contains 1,459 examples and 80 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "THmf3WyP27PM",
    "outputId": "2fd7c73d-e03d-403f-bbea-328410ce9630"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 81)\n",
      "(1459, 80)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4fxMHe1k3BzZ"
   },
   "source": [
    "Let’s take a look at the first 4 and last 2 features as well as the label (SalePrice) from the first 4 examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 171
    },
    "colab_type": "code",
    "id": "6sfz9Gtl3C1b",
    "outputId": "336e9d09-15d6-4a07-f1fb-26308424d35c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage SaleType SaleCondition  SalePrice\n",
       "0   1          60       RL         65.0       WD        Normal     208500\n",
       "1   2          20       RL         80.0       WD        Normal     181500\n",
       "2   3          60       RL         68.0       WD        Normal     223500\n",
       "3   4          70       RL         60.0       WD       Abnorml     140000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.iloc[0:4, [0, 1, 2, 3, -3, -2, -1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HwTwT20T3KAt"
   },
   "source": [
    "We can see that in each example, the first feature is the ID. This helps the model identify each training example. While this is convenient, it doesn't carry any information for prediction purposes. Hence we remove it from the dataset before feeding the data into the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0WZmJ9Cp3JeZ"
   },
   "outputs": [],
   "source": [
    "all_features = pd.concat((train_data.iloc[:, 1:-1], test_data.iloc[:, 1:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ui1WxgCg3Q1E"
   },
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "As stated above, we have a wide variety of datatypes. Before we feed it into a deep network we need to perform some amount of processing. Let's start with the numerical features. We begin by replacing missing values with the mean. This is a reasonable strategy if features are missing at random. To adjust them to a common scale we rescale them to zero mean and unit variance. This is accomplished as follows:\n",
    "\n",
    "$$x \\leftarrow \\frac{x - \\mu}{\\sigma}$$\n",
    "\n",
    "To check that this transforms $x$ to data with zero mean and unit variance simply calculate $\\mathbf{E}[(x-\\mu)/\\sigma] = (\\mu - \\mu)/\\sigma = 0$. To check the variance we use $\\mathbf{E}[(x-\\mu)^2] = \\sigma^2$ and thus the transformed variable has unit variance. The reason for 'normalizing' the data is that it brings all features to the same order of magnitude. After all, we do not know *a priori* which features are likely to be relevant. Hence it makes sense to treat them equally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R4ZFD_zD3STa"
   },
   "outputs": [],
   "source": [
    "# We are going to first select all of the columns with integer or float \n",
    "numerical_cols = all_features.select_dtypes(include=['int64', 'float64'])\n",
    "\n",
    "#However, the following are actually classes, so we are going to remove them from our normalization \n",
    "numerical_cols = numerical_cols.drop(['MSSubClass', 'OverallQual', 'OverallCond', 'MoSold'], axis=1)\n",
    "\n",
    "#Now perform the normalization only to the true numerical columns \n",
    "all_features = all_features.apply(lambda x: (x-x.mean())/x.std() if x.name in numerical_cols.columns else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after standardizing the data all means vanish, hence we can set missing values to 0\n",
    "all_features = all_features.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aiM9DPGK3xGm"
   },
   "source": [
    "Next we deal with discrete values. This includes variables such as 'MSZoning'. We replace them by a one-hot encoding in the same manner as how we transformed multiclass classification data into a vector of $0$ and $1$. For instance, 'MSZoning' assumes the values 'RL' and 'RM'. They map into vectors $(1,0)$ and $(0,1)$ respectively. Pandas does this automatically for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's identify the class variables, these are going to be all the variables which weren't included in the numerical\n",
    "#columns which we found before and normalized. Also, we don't want to transform the index\n",
    "categorical_cols = list(numerical_cols.columns)\n",
    "all_features.index.name = 'Index'\n",
    "categorical_cols.append(all_features.index.name)\n",
    "categorical_cols = np.setdiff1d(list(all_features.columns),categorical_cols)\n",
    "\n",
    "all_features = pd.get_dummies(data=all_features, columns=categorical_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "5adavFft3yc9",
    "outputId": "9fcb2f17-81d6-4049-f63b-15579afc98ea"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2919, 354)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ftmtYZnK4aTz"
   },
   "source": [
    "You can see that this conversion increases the number of features from 79 to 354. Finally, via the values attribute we can extract the NumPy format from the Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JepAWRlO4J5n"
   },
   "outputs": [],
   "source": [
    "n_train = train_data.shape[0]\n",
    "train_features = all_features[:n_train].values\n",
    "test_features = all_features[n_train:].values\n",
    "train_labels = train_data.SalePrice.values.reshape((-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ytjd37es4vtq"
   },
   "source": [
    "## Training\n",
    "\n",
    "To get started we train a linear model with squared loss. This will obviously not lead to a competition winning submission but it provides a sanity check to see whether there's meaningful information in the data. It also amounts to a minimum baseline of how well we should expect any 'fancy' model to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WED8M73t4wsu"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, SGDRegressor, RidgeCV\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "fBqU5YLF8gxg",
    "outputId": "6d69953c-ae0f-4526-c4fc-90015cdb79a0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9391177350313022"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = LinearRegression()\n",
    "reg.fit(train_features, train_labels)\n",
    "reg.score(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#My attempt at a better model\n",
    "regD = DecisionTreeRegressor()\n",
    "regD.fit(train_features, train_labels.ravel())\n",
    "regD.score(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DoV4Ox2K9nm3"
   },
   "source": [
    "##  Predict and Submit\n",
    "\n",
    "Now that we know what a good choice of hyperparameters should be, we might as well use all the data to train on it (rather than just $1-1/k$ of the data that is used in the crossvalidation slices). The model that we obtain in this way can then be applied to the test set. Saving the estimates in a CSV file will simplify uploading the results to Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Saps5iS9okQ"
   },
   "outputs": [],
   "source": [
    "def train_and_pred(test_feature, test_data,):\n",
    "    preds = regD.predict(test_features)\n",
    "    # reformat it for export to Kaggle\n",
    "    test_data['SalePrice'] = pd.Series(preds.reshape(1, -1)[0])\n",
    "    submission = pd.concat([test_data['Id'], test_data['SalePrice']], axis=1)\n",
    "    submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gb2BJDmU-GWU"
   },
   "outputs": [],
   "source": [
    "train_and_pred(test_features, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X8bHvMd1--Tv"
   },
   "source": [
    "A file, `submission.csv` will be generated by the code above (CSV is one of the file formats accepted by Kaggle).  Next, we can submit our predictions on Kaggle and compare them to the actual house price (label) on the testing data set, checking for errors. The steps are quite simple:\n",
    "\n",
    "* Log in to the Kaggle website and visit the House Price Prediction Competition page.\n",
    "* Click the “Submit Predictions” or “Late Submission” button on the right.\n",
    "* Click the “Upload Submission File” button in the dashed box at the bottom of the page and select the prediction file you wish to upload.\n",
    "* Click the “Make Submission” button at the bottom of the page to view your results.\n",
    "\n",
    "![](submit.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RXZ9Wsd__Afe"
   },
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "HW1_house_price_prediction_sol.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
